{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5cc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db5b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"d:\\moje_dokumenty\\Desktop\\matfyz\\mgr\\semester 11\\Projektovy seminar\\Q01_HL_23.csv\", skiprows=[0,1,2, 3],\n",
    "                   names = [\"date\",\" Hl-Vega-OK\", \"Hl-US-Odlehc\", \"Hladina KDO\", \"Teplota KDO\", \n",
    "                                       \"Rychlost KDO\", \"Prietok_l\", \"Napatie_AKU2\", \"Napatie_AKU\",  \"Prietok\"],\n",
    "                  sep = \";\", decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c60ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.read_csv(\"d:\\moje_dokumenty\\Desktop\\matfyz\\mgr\\semester 11\\Projektovy seminar\\SR02_H2_27374.csv\", skiprows=[0,1,2, 3],\n",
    "                  usecols = [0,1], names = [\"date\",\"rain\"],\n",
    "                  sep = \";\", decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad080e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = pd.to_datetime(data['date'], format='%d.%m.%Y %H:%M:%S')\n",
    "rain[\"date\"] = pd.to_datetime(rain['date'], format='%d.%m.%Y %H:%M:%S')\n",
    "rain.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "rain[\"rain\"] = pd.to_numeric(rain[\"rain\"].str.replace(',', '.') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3360b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.set_index('date', inplace=True)\n",
    "\n",
    "# Resample data to two-minute intervals and calculate the sum for each two-minute period\n",
    "rain['rain_2m'] = rain['rain'].resample('2T').sum()\n",
    "\n",
    "# Assign NaN to odd minutes\n",
    "rain['rain_2m'][rain.index.minute % 2 != 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82de849",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain[\"date\"] = rain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71fef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:01:00\n",
      "0 days 00:10:00\n",
      "0 days 00:10:00    4155\n",
      "0 days 00:01:00    2496\n",
      "0 days 00:04:00      20\n",
      "0 days 00:07:00      16\n",
      "0 days 00:06:00      16\n",
      "0 days 00:02:00      14\n",
      "0 days 00:09:00      14\n",
      "0 days 00:03:00      13\n",
      "0 days 00:08:00       9\n",
      "0 days 00:05:00       8\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rain['date'].diff().dropna().min())\n",
    "print(rain['date'].diff().dropna().max())\n",
    "print(rain['date'].diff().dropna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d89cb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:02:00\n",
      "0 days 00:04:00\n",
      "0 days 00:02:00    22317\n",
      "0 days 00:04:00        1\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['date'].diff().dropna().min())\n",
    "print(data['date'].diff().dropna().max())\n",
    "print(data['date'].diff().dropna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fa6722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['date'].dt.minute % 2 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df20e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.index = range(rain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764ee3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>rain_2m</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 23:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2022-05-31 23:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 23:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-31 23:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 23:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2022-05-31 23:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 23:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-31 23:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 23:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2022-05-31 23:10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rain  rain_2m                date\n",
       "0   0.0      NaN 2022-05-31 23:01:00\n",
       "1   0.1      0.1 2022-05-31 23:02:00\n",
       "2   0.0      NaN 2022-05-31 23:03:00\n",
       "3   0.0      0.0 2022-05-31 23:04:00\n",
       "4   0.0      NaN 2022-05-31 23:05:00\n",
       "5   0.1      0.1 2022-05-31 23:06:00\n",
       "6   0.0      NaN 2022-05-31 23:07:00\n",
       "7   0.0      0.0 2022-05-31 23:08:00\n",
       "8   0.0      NaN 2022-05-31 23:09:00\n",
       "9   0.0      0.1 2022-05-31 23:10:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c254e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(rain, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57faf79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Hl-Vega-OK</th>\n",
       "      <th>Hl-US-Odlehc</th>\n",
       "      <th>Hladina KDO</th>\n",
       "      <th>Teplota KDO</th>\n",
       "      <th>Rychlost KDO</th>\n",
       "      <th>Prietok_l</th>\n",
       "      <th>Napatie_AKU2</th>\n",
       "      <th>Napatie_AKU</th>\n",
       "      <th>Prietok</th>\n",
       "      <th>rain</th>\n",
       "      <th>rain_2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-31 23:02:00</td>\n",
       "      <td>349</td>\n",
       "      <td></td>\n",
       "      <td>320</td>\n",
       "      <td>14</td>\n",
       "      <td>0.56</td>\n",
       "      <td>114.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-31 23:04:00</td>\n",
       "      <td>349</td>\n",
       "      <td></td>\n",
       "      <td>319</td>\n",
       "      <td>14</td>\n",
       "      <td>0.51</td>\n",
       "      <td>102.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-31 23:06:00</td>\n",
       "      <td>352</td>\n",
       "      <td></td>\n",
       "      <td>320</td>\n",
       "      <td>14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>98.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11.87</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-31 23:08:00</td>\n",
       "      <td>352</td>\n",
       "      <td></td>\n",
       "      <td>322</td>\n",
       "      <td>14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>99.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-31 23:10:00</td>\n",
       "      <td>353</td>\n",
       "      <td></td>\n",
       "      <td>325</td>\n",
       "      <td>14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>101.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date   Hl-Vega-OK Hl-US-Odlehc  Hladina KDO  Teplota KDO  \\\n",
       "0 2022-05-31 23:02:00          349                       320           14   \n",
       "1 2022-05-31 23:04:00          349                       319           14   \n",
       "2 2022-05-31 23:06:00          352                       320           14   \n",
       "3 2022-05-31 23:08:00          352                       322           14   \n",
       "4 2022-05-31 23:10:00          353                       325           14   \n",
       "\n",
       "   Rychlost KDO  Prietok_l Napatie_AKU2 Napatie_AKU  Prietok  rain  rain_2m  \n",
       "0          0.56      114.6                             13.75   0.1      0.1  \n",
       "1          0.51      102.3                             12.28   0.0      0.0  \n",
       "2          0.49       98.9                             11.87   0.1      0.1  \n",
       "3          0.49       99.4                             11.93   0.0      0.0  \n",
       "4          0.50      101.6                             12.19   0.0      0.1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f03ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hl-Vega-OK</th>\n",
       "      <th>Hladina KDO</th>\n",
       "      <th>Teplota KDO</th>\n",
       "      <th>Rychlost KDO</th>\n",
       "      <th>Prietok_l</th>\n",
       "      <th>Prietok</th>\n",
       "      <th>rain</th>\n",
       "      <th>rain_2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22319.000000</td>\n",
       "      <td>22319.000000</td>\n",
       "      <td>22319.000000</td>\n",
       "      <td>22319.000000</td>\n",
       "      <td>22319.000000</td>\n",
       "      <td>22319.000000</td>\n",
       "      <td>1304.000000</td>\n",
       "      <td>5484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>185.552310</td>\n",
       "      <td>192.835476</td>\n",
       "      <td>15.688517</td>\n",
       "      <td>0.263786</td>\n",
       "      <td>29.987177</td>\n",
       "      <td>3.598630</td>\n",
       "      <td>0.050613</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.118763</td>\n",
       "      <td>91.678332</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.113476</td>\n",
       "      <td>34.873107</td>\n",
       "      <td>4.185152</td>\n",
       "      <td>0.132684</td>\n",
       "      <td>0.128841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>794.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>326.300000</td>\n",
       "      <td>39.150000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Hl-Vega-OK   Hladina KDO   Teplota KDO  Rychlost KDO     Prietok_l  \\\n",
       "count  22319.000000  22319.000000  22319.000000  22319.000000  22319.000000   \n",
       "mean     185.552310    192.835476     15.688517      0.263786     29.987177   \n",
       "std       77.118763     91.678332      0.995117      0.113476     34.873107   \n",
       "min        0.000000    100.000000     13.000000     -0.090000      0.000000   \n",
       "25%      157.000000    139.000000     15.000000      0.160000     12.800000   \n",
       "50%      170.000000    180.000000     16.000000      0.270000     21.000000   \n",
       "75%      182.000000    221.000000     16.000000      0.350000     34.100000   \n",
       "max      794.000000    970.000000     19.000000      0.800000    326.300000   \n",
       "\n",
       "            Prietok         rain      rain_2m  \n",
       "count  22319.000000  1304.000000  5484.000000  \n",
       "mean       3.598630     0.050613     0.023359  \n",
       "std        4.185152     0.132684     0.128841  \n",
       "min        0.000000     0.000000     0.000000  \n",
       "25%        1.540000     0.000000     0.000000  \n",
       "50%        2.520000     0.000000     0.000000  \n",
       "75%        4.090000     0.100000     0.000000  \n",
       "max       39.150000     1.700000     3.300000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6011cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>rain_2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2581.000000</td>\n",
       "      <td>5485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.023355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133948</td>\n",
       "      <td>0.128830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.700000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rain      rain_2m\n",
       "count  2581.000000  5485.000000\n",
       "mean      0.050794     0.023355\n",
       "std       0.133948     0.128830\n",
       "min       0.000000     0.000000\n",
       "25%       0.000000     0.000000\n",
       "50%       0.000000     0.000000\n",
       "75%       0.100000     0.000000\n",
       "max       1.700000     3.300000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6408775e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22319, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d05a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6762, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f424c41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                0\n",
       " Hl-Vega-OK         0\n",
       "Hl-US-Odlehc        0\n",
       "Hladina KDO         0\n",
       "Teplota KDO         0\n",
       "Rychlost KDO        0\n",
       "Prietok_l           0\n",
       "Napatie_AKU2        0\n",
       "Napatie_AKU         0\n",
       "Prietok             0\n",
       "rain            21015\n",
       "rain_2m         16835\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7548486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[\"Prietok\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badee30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5373ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "49d8db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS_Class:\n",
    "    \n",
    "    def __init__(self, data, main_var = \"Prietok\", \n",
    "                 start_date = None, end_date = None, periodicity = \"2T\", check_per = True):\n",
    "        if start_date is None:\n",
    "            start_date = data[\"date\"].min()\n",
    "        if end_date is None:\n",
    "            end_date = data[\"date\"].max()\n",
    "        date_range = pd.date_range(start=start_date, end=end_date, freq=periodicity)\n",
    "        df = pd.DataFrame({'date': date_range})\n",
    "        self.data = df.merge(data, on='date', how='left')   # ensuring we have constant periodicity in observations\n",
    "        if not check_per:\n",
    "            self.data = data\n",
    "        self.main_var = main_var\n",
    "        self.data[main_var + \"_diff_1\"] = data[main_var].diff()\n",
    "        self.data[main_var + \"_diff_2\"] = self.data[main_var + \"_diff_1\"].diff()\n",
    "        self.models = {}\n",
    "        \n",
    "    def get_period_data(self, period, start_time = None, which = 1, subset = None):\n",
    "        \"\"\"Period is either 'daily', 'weekly', or whole number indicating number of hours.\"\"\"\n",
    "        used_data = self.data.copy() if subset is None else self.data.iloc[subset,].copy()\n",
    "        if type(period) == int:\n",
    "            if start_time is None or start_time == \"start\":\n",
    "                reference_point = used_data[\"date\"].min()\n",
    "            else:\n",
    "                start_time = datetime.strptime(start_time, \"%H:%M:%S\")\n",
    "                reference_point = used_data[used_data['date'].dt.time == start_time.time()][\"date\"].min()\n",
    "                used_data = used_data[used_data[\"date\"]>= reference_point]    # cut off observations before start_time\n",
    "            used_data[\"period_index\"] = used_data[\"date\"].apply(lambda x: (x-reference_point).total_seconds() // (period * 3600))\n",
    "            used_data[\"period_name\"] = used_data[\"period_index\"].apply(\n",
    "                lambda x:f\"[{reference_point + timedelta(hours=period*x)} -- {reference_point + timedelta(hours=period*(x+1))})\")\n",
    "        \n",
    "        elif period == \"daily\":\n",
    "            used_data['period_name'] = used_data['date'].dt.date\n",
    "            \n",
    "        elif period == \"weekly\":\n",
    "            first = used_data['date'].dt.strftime('%Y-%W').apply(\n",
    "                lambda x: x.split(\"-\")).apply(\n",
    "                lambda y: datetime.strptime(f'{y[0]}-W{y[1]}-1', \"%Y-W%U-%w\") )\n",
    "            used_data['period_name'] = first.apply(\n",
    "                lambda x: f\"{x.strftime('%Y-%m-%d')} -- {(x+timedelta(days=6)).strftime('%Y-%m-%d')}\")\n",
    "                       \n",
    "        else:\n",
    "            raise NameError('Period which is not recognized have been entered. \"weekly\" or \"daily\" are expected.')\n",
    "        \n",
    "        if which == 1:\n",
    "            self.period_data = used_data.groupby('period_name')\n",
    "        else:\n",
    "            self.period_data_2 = used_data.groupby('period_name')\n",
    "        \n",
    "    def get_y_lim(self, value, negative = False):\n",
    "        if negative:\n",
    "            value = - value\n",
    "        if value < 5: return 5\n",
    "        if value < 10: return 10\n",
    "        if value < 20: return 20\n",
    "        return value*1.1\n",
    "    \n",
    "    def get_rob_subset(self, variable, rob_quantile, two_sided):\n",
    "        subset = self.data[variable] < self.data[variable].quantile(rob_quantile)\n",
    "        if two_sided:\n",
    "            L = self.data[variable].quantile(1-rob_quantile)\n",
    "            U = self.data[variable].quantile(rob_quantile)\n",
    "            subset =  self.data[variable].apply(lambda x: L<x<U)\n",
    "        return subset\n",
    "    \n",
    "    def get_measures(self, variable, include, window, which = 1, \n",
    "                     quantile = 0.5, rob_quantile = 0.8, two_sided_rob_q = False, rob_q_mult = 1):   \n",
    "        suff = \"\" if which == 1 else \"_2\"\n",
    "        if two_sided_rob_q:\n",
    "            rob_quantile = 0.5 + rob_quantile/2\n",
    "        if \"CMA\" in include:\n",
    "            self.data['Centered_Moving_Average'+suff] = self.data[variable].rolling(window=window, center=True).mean()\n",
    "        if (\"CMA_bounds\" in include) or (\"CMA_bounds_2sd\" in include):\n",
    "            self.data['Centered_Moving_Average'+suff] = self.data[variable].rolling(window=window, center=True).mean()\n",
    "            self.data['Centered_Moving_SD'+suff] = self.data[variable].rolling(window=window, center=True).std()\n",
    "            self.data['CMA_upper'+suff] = self.data['Centered_Moving_Average'+suff] + self.data['Centered_Moving_SD'+suff]\n",
    "            self.data['CMA_lower'+suff] = self.data['Centered_Moving_Average'+suff] - self.data['Centered_Moving_SD'+suff]\n",
    "            if \"CMA_bounds_2sd\" in include:\n",
    "                self.data['CMA_upper_2sd'+suff] = self.data['Centered_Moving_Average'+suff] + 2*self.data['Centered_Moving_SD'+suff]\n",
    "                self.data['CMA_lower_2sd'+suff] = self.data['Centered_Moving_Average'+suff] - 2*self.data['Centered_Moving_SD'+suff]\n",
    "        if \"CMA_rob_bounds\"  in include:\n",
    "            self.data['Centered_Moving_Average'+suff] = self.data[variable].rolling(window=window, center=True).mean()\n",
    "            subset = self.get_rob_subset(variable, rob_quantile, two_sided_rob_q)\n",
    "            robust_sd = self.data[subset][variable].std()\n",
    "            self.data['CMA_upper_rob'+suff] = self.data['Centered_Moving_Average'+suff] + rob_q_mult*robust_sd\n",
    "            self.data['CMA_lower_rob'+suff] = self.data['Centered_Moving_Average'+suff] - rob_q_mult*robust_sd\n",
    "                \n",
    "        if \"MA\" in include:\n",
    "            self.data['Moving_Average'+suff] = self.data[variable].rolling(window=window, center=False).mean()\n",
    "        if (\"MA_bounds\" in include) or (\"MA_bounds_2sd\" in include):\n",
    "            self.data['Moving_Average'+suff] = self.data[variable].rolling(window=window, center=False).mean()\n",
    "            self.data['Moving_SD'+suff] = self.data[variable].rolling(window=window, center=False).std()\n",
    "            self.data['MA_upper'+suff] = self.data['Moving_Average'+suff] + self.data['Moving_SD'+suff]\n",
    "            self.data['MA_lower'+suff] = self.data['Moving_Average'+suff] - self.data['Moving_SD'+suff]\n",
    "            if \"MA_bounds_2sd\" in include:\n",
    "                self.data['MA_upper_2sd'+suff] = self.data['Moving_Average'+suff] + 2*self.data['Moving_SD'+suff]\n",
    "                self.data['MA_lower_2sd'+suff] = self.data['Moving_Average'+suff] - 2*self.data['Moving_SD'+suff]\n",
    "        if \"MA_rob_bounds\" in include:\n",
    "            self.data['Moving_Average'+suff] = self.data[variable].rolling(window=window, center=False).mean()\n",
    "            subset = self.get_rob_subset(variable, rob_quantile, two_sided_rob_q)\n",
    "            robust_sd = self.data[subset][variable].std()\n",
    "            self.data['MA_upper_rob'+suff] = self.data['Moving_Average'+suff] + rob_q_mult*robust_sd\n",
    "            self.data['MA_lower_rob'+suff] = self.data['Moving_Average'+suff] - rob_q_mult*robust_sd\n",
    "        \n",
    "        if \"CMSD\" in include:\n",
    "            self.data['Centered_Moving_SD'+suff] = self.data[variable].rolling(window=window, center=True).std()\n",
    "        if \"MSD\" in include:\n",
    "            self.data['Moving_SD'+suff] = self.data[variable].rolling(window=window, center=False).std()\n",
    "        if \"tot_avg\" in include:\n",
    "            self.data['total_avg'+suff] = self.data[variable].mean()\n",
    "        if \"quant\" in include:\n",
    "            self.data['quantile'+suff] = self.data[variable].quantile(quantile)\n",
    "        if \"robust_avg\" in include:\n",
    "            subset = self.get_rob_subset(variable, rob_quantile, two_sided_rob_q)\n",
    "            self.data['r_avg'+suff] = self.data[subset][variable].mean()\n",
    "            \n",
    "    \n",
    "    def get_ax(self, ax, group_data, unit, variable, include, rain_lims, which, include_rain = True, marker = None):  \n",
    "        suff = \"\" if which == 1 else \"_2\"\n",
    "        ax.plot(group_data['date'], group_data[variable], label = variable)\n",
    "        if \"CMA\" in include:\n",
    "            ax.plot(group_data['date'], group_data['Centered_Moving_Average'+suff], color=\"red\", label = \"CMA\")\n",
    "            include.remove(\"CMA\")\n",
    "        \n",
    "        if \"CMA_bounds_2sd\" in include:\n",
    "            ax.plot(group_data['date'], group_data['CMA_upper_2sd'+suff], color=\"orange\", label = \"CMA_Up\")\n",
    "            ax.plot(group_data['date'], group_data['CMA_lower_2sd'+suff], color=\"orange\", label = \"CMA_L\")\n",
    "            include.remove(\"CMA_bounds_2sd\")\n",
    "        if \"CMA_bounds\" in include:\n",
    "            ax.plot(group_data['date'], group_data['CMA_upper'+suff], color=\"orange\", label = \"CMA_Up\")\n",
    "            ax.plot(group_data['date'], group_data['CMA_lower'+suff], color=\"orange\", label = \"CMA_L\")\n",
    "            include.remove(\"CMA_bounds\")\n",
    "        \n",
    "        if \"CMA_rob_bounds\" in include:\n",
    "            ax.plot(group_data['date'], group_data['CMA_upper_rob'+suff], color=\"black\", label = \"CMA_rob_Up\")\n",
    "            ax.plot(group_data['date'], group_data['CMA_lower_rob'+suff], color=\"black\", label = \"CMA_rob_L\")\n",
    "            include.remove(\"CMA_rob_bounds\")\n",
    "            \n",
    "        if \"MA\" in include:\n",
    "            ax.plot(group_data['date'], group_data['Moving_Average'+suff], color=\"brown\", label = \"MA\")\n",
    "            include.remove(\"MA\")\n",
    "        if \"MA_bounds\" in include:\n",
    "            ax.plot(group_data['date'], group_data['MA_upper'+suff], color=\"yellow\", label = \"MA_Up\")\n",
    "            ax.plot(group_data['date'], group_data['MA_lower'+suff], color=\"yellow\", label = \"MA_L\")\n",
    "            include.remove(\"MA_bounds\")\n",
    "        if \"MA_bounds_2sd\" in include:\n",
    "            ax.plot(group_data['date'], group_data['MA_upper_2sd'+suff], color=\"yellow\", label = \"MA_Up\")\n",
    "            ax.plot(group_data['date'], group_data['MA_lower_2sd'+suff], color=\"yellow\", label = \"MA_L\")\n",
    "            include.remove(\"MA_bounds_2sd\")\n",
    "        if \"MA_rob_bounds\" in include:\n",
    "            ax.plot(group_data['date'], group_data['MA_upper_rob'+suff], color=\"black\", label = \"MA_rob_Up\")\n",
    "            ax.plot(group_data['date'], group_data['MA_lower_rob'+suff], color=\"black\", label = \"MA_rob_L\")\n",
    "            include.remove(\"MA_rob_bounds\")\n",
    "            \n",
    "        if \"CMSD\" in include:\n",
    "            ax.plot(group_data['date'], group_data['Centered_Moving_SD'+suff], color=\"green\", label = \"CMSD\")\n",
    "            include.remove(\"CMSD\")\n",
    "        if \"MSD\" in include:\n",
    "            ax.plot(group_data['date'], group_data['Moving_SD'+suff], color=\"black\", label = \"MSD\")\n",
    "            include.remove(\"MSD\")\n",
    "        if \"tot_avg\" in include:\n",
    "            ax.plot(group_data['date'], group_data['total_avg'+suff], color=\"black\", label = \"tot_avg\")\n",
    "            include.remove(\"tot_avg\")\n",
    "        if \"quant\" in include:\n",
    "            ax.plot(group_data['date'], group_data['quantile'+suff], color=\"black\", label = \"quantile\")\n",
    "            include.remove(\"quant\")\n",
    "        if \"robust_avg\" in include:\n",
    "            ax.plot(group_data['date'], group_data['r_avg'+suff], color=\"black\", label = \"robust_avg\")\n",
    "            include.remove(\"robust_avg\")\n",
    "        \n",
    "        max_y = group_data[variable].max()\n",
    "        min_y = group_data[variable].min()\n",
    "        #print(variable+str(min_y))    #########\n",
    "        #print(variable+str(max_y))    #########\n",
    "        #print(variable+\" no-nan \"+str(max_y))    #########\n",
    "        for item in include:\n",
    "            if item in group_data.columns:\n",
    "                ax.plot(group_data['date'], group_data[item], label = item)\n",
    "                max_y = max(max_y, group_data[item].max())\n",
    "                min_y = min(min_y, group_data[item].min())\n",
    "                #print(item+str(min_y))    #########\n",
    "               # print(item+str(max_y))    #########\n",
    "                        \n",
    "        ax.set_title(f'Time Series for {unit}')\n",
    "        ax.set_xlabel('Date and Time')\n",
    "        ax.set_ylabel(variable)\n",
    "        ax.legend(loc=\"upper left\")\n",
    "        ylim_up = self.get_y_lim(max_y)\n",
    "        ylim_down = -self.get_y_lim(min_y, True) if min_y < 0 else 0\n",
    " #       print(\"down \"+str(ylim_down))            ##############\n",
    " #       print(\"up \"+str(ylim_up))\n",
    "        try:\n",
    "            ax.set_ylim(ylim_down, ylim_up)\n",
    "        except:\n",
    "            print(\"down \"+str(ylim_down))            ##############\n",
    "            print(\"up \"+str(min_y))\n",
    "        for line in ax.lines:\n",
    "            line.set_marker(marker)\n",
    "            \n",
    "        if include_rain:\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.set_ylim(*rain_lims)\n",
    "            ax2.plot(group_data[\"date\"], group_data['rain_2m'], label='rain', color='green')\n",
    "            ax2.invert_yaxis()\n",
    "            ax2.set_ylabel('rain (Upside-Down)', color='green')\n",
    "            ax2.tick_params(axis='y', labelcolor='green')\n",
    "            ax2.legend(loc='upper right')\n",
    "            return (ax, ax2)\n",
    "        return (ax, \"\")\n",
    "        \n",
    "    def plot(self, variable = None, period = \"all\", start_time = None, subset = None, \n",
    "             quantile = 0.5, rob_quantile = 0.8, two_sided_rob_q = False, rob_q_mult = 1,\n",
    "             include = [\"CMA\", \"CMA_bounds\"], window = 30, rain_lims = (0,5), fig_size = None, \n",
    "            variable_2 = None, start_time_2 = None, include_2 = [\"CMA\", \"CMA_bounds\"], window_2 = 30, \n",
    "            quantile_2 = 0.5, rob_quantile_2 = 0.8, two_sided_rob_q_2 = False, rob_q_mult_2 = 1, \n",
    "             double_plot = False, include_rain = True, marker = None):\n",
    "        if variable is None:\n",
    "            variable = self.main_var\n",
    "        \n",
    "        self.get_measures(variable, include, window, which = 1, quantile = quantile, rob_quantile = rob_quantile, \n",
    "                          two_sided_rob_q = two_sided_rob_q, rob_q_mult = rob_q_mult)\n",
    "        if start_time_2 is not None:\n",
    "            if variable_2 is None: variable_2 = variable\n",
    "            self.get_measures(variable_2, include_2, window_2, which = 2, quantile = quantile_2, \n",
    "                              rob_quantile = rob_quantile_2, two_sided_rob_q = two_sided_rob_q_2, rob_q_mult = rob_q_mult_2)\n",
    "                \n",
    "        if period == \"all\":\n",
    "            self.data[\"const\"] = \"whole data\"\n",
    "            used_data = self.data.copy() if subset is None else self.data.iloc[subset,].copy()\n",
    "            self.period_data = used_data.groupby(\"const\")\n",
    "        else:\n",
    "            self.get_period_data(period, start_time, 1, subset)\n",
    "        \n",
    "        if start_time_2 is None:\n",
    "            self.period_data_2 = self.period_data\n",
    "        else:\n",
    "            if period == \"all\":\n",
    "                self.data[\"const\"] = \"whole data\"\n",
    "                used_data = self.data.copy() if subset is None else self.data.iloc[subset,].copy()\n",
    "                self.period_data_2 = used_data.groupby(\"const\")\n",
    "            else:\n",
    "                self.get_period_data(period, start_time_2, 2, subset)\n",
    "            \n",
    "        for grouped_1, grouped_2 in zip(self.period_data,self.period_data_2):\n",
    "            unit_1, group_data_1 = grouped_1\n",
    "            unit_2, group_data_2 = grouped_2\n",
    "            \n",
    "            if double_plot:\n",
    "                group_data_1.set_index('date', inplace=True)\n",
    "                group_data_2.set_index('date', inplace=True)\n",
    "                group_data_1[variable].plot(xlabel = 'Date and Time', ylabel = variable, label = variable)\n",
    "                group_data_2[variable_2].plot(label = variable_2)\n",
    "                \n",
    "                plt.title(f'Time Series for {unit_1}')\n",
    "                plt.legend(loc=\"upper left\")\n",
    "                plt.show()\n",
    "                continue\n",
    "            \n",
    "            if start_time_2 is not None:\n",
    "                if fig_size is None: \n",
    "                    fig_size = (19, 6)\n",
    "                fig, ax = plt.subplots(1, 2, figsize=fig_size)\n",
    "                ax[0], axb1 = self.get_ax(ax[0], group_data_1, unit_1, variable, include, rain_lims, 1, include_rain, marker)\n",
    "                ax[1], axb2 = self.get_ax(ax[1], group_data_2, unit_2, variable_2, include_2, rain_lims, 2, include_rain, marker)\n",
    "            else:\n",
    "                if fig_size is None: \n",
    "                    fig_size = (10, 6)\n",
    "                fig, ax = plt.subplots(figsize=fig_size)\n",
    "                ax, axb1 = self.get_ax(ax, group_data_1, unit_1, variable, include, rain_lims, 1, include_rain, marker)\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "    def groupby(self, groupby):\n",
    "        if groupby is None:\n",
    "            self.data[\"const\"] = \"whole data\"\n",
    "            grouped = self.data.groupby(\"const\")\n",
    "        else:\n",
    "            if groupby == \"daily\":\n",
    "                self.data['period_name'] = self.data['date'].dt.date\n",
    "                grouped = self.data.groupby(\"period_name\")\n",
    "            elif groupby == \"weekly\":\n",
    "                self.data['period_name'] = self.data['date'].dt.strftime('%Y-%W')\n",
    "                grouped = self.data.groupby(\"period_name\")\n",
    "            else:\n",
    "                grouped = self.data.groupby(groupby)\n",
    "        return grouped\n",
    "    \n",
    "    def get_ETS(self, variable, model_name, groupby = None, show_progress = True,\n",
    "                error=\"add\", trend=\"add\", seasonal=\"add\", damped_trend=False, seasonal_periods=720):\n",
    "        \"\"\"Note: there is 720 observations per day, for 1 day periodicity we need 720 seasonal components, which is too \n",
    "        many for practical estimatation - careful about seasonal components.\"\"\"\n",
    "        self.data[model_name + \"_fitted\"] = np.nan\n",
    "        self.models[model_name] = []\n",
    "        i = -1\n",
    "        grouped = self.groupby(groupby)\n",
    "                        \n",
    "        length = len(grouped)\n",
    "        for unit, grouped_data in grouped:\n",
    "            model = ETSModel(grouped_data[variable], error=error, trend=trend, seasonal=seasonal, \n",
    "                                            damped_trend=damped_trend, seasonal_periods=seasonal_periods)\n",
    "            result = model.fit()\n",
    "            grouped_data[model_name + \"_fitted\"] = result.fittedvalues\n",
    "            self.models[model_name].append((unit, model, results))\n",
    "            self.data.loc[grouped_data.index,model_name + \"_fitted\"] = grouped_data[model_name + \"_fitted\"]\n",
    "            if show_progress:\n",
    "                i += 1\n",
    "                if i%5 == 0:\n",
    "                    print(f\"{i+1} out of {length} ({(i+1)*100/length}%)\")\n",
    "                    \n",
    "    def get_ARIMA(self, p, d, q, model_name, variable = None,  groupby = None, show_progress = True):\n",
    "        if variable is None: variable = self.main_var\n",
    "        self.data[model_name + \"_fitted\"] = np.nan\n",
    "        self.models[model_name] = []\n",
    "        i = -1\n",
    "        grouped = self.groupby(groupby)           \n",
    "        length = len(grouped)\n",
    "        for unit, grouped_data in grouped:\n",
    "            model = ARIMA(grouped_data[variable], order=(p, d, q))\n",
    "            results = model.fit()\n",
    "            grouped_data[model_name + \"_fitted\"] = results.fittedvalues\n",
    "            self.models[model_name].append((unit, model, results))\n",
    "            self.data.loc[grouped_data.index,model_name + \"_fitted\"] = grouped_data[model_name + \"_fitted\"]\n",
    "            if show_progress:\n",
    "                i += 1\n",
    "                if i%5 == 0:\n",
    "                    print(f\"{i+1} out of {length} ({(i+1)*100/length}%)\")\n",
    "                    \n",
    "    def ARIMA_diagnostics(self, results, unit, model_name, show_summary = True):\n",
    "        print(\"ARIMA diagnostics for \" + model_name + \" \" + str(unit))\n",
    "        if show_summary:\n",
    "            print(results.summary())\n",
    "        residuals = results.resid\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        ax[0, 0].plot(residuals)\n",
    "        ax[0, 0].set_title('Residuals')\n",
    "        lags_1 = min(40, len(residuals)-1)\n",
    "        lags_2 = min(40, int(len(residuals)/2)-2)\n",
    "        sm.graphics.tsa.plot_acf(residuals, lags=lags_1, ax=ax[0, 1])\n",
    "        sm.graphics.tsa.plot_pacf(residuals, lags=lags_2, ax=ax[1, 0])\n",
    "        plt.show()\n",
    "\n",
    "        # Ljung-Box test for autocorrelation in residuals\n",
    "        acf, q_val, p_val = sm.tsa.acf(residuals, fft=True, qstat=True)\n",
    "        p_val_df = pd.DataFrame({'Lag': range(1, len(p_val) + 1), 'P-Value': p_val})\n",
    "\n",
    "        print(p_val_df)\n",
    "    \n",
    "    def ARIMAs_diagnostics(self, model_name, subset = None):\n",
    "        models = self.models[model_name]\n",
    "        if subset is not None:\n",
    "            models = models[subset]\n",
    "        for unit, mod, res in models:\n",
    "            self.ARIMA_diagnostics(res, unit, model_name)\n",
    "            \n",
    "    def get_time_trend(self, values, give = \"slope\"):\n",
    "        \"\"\"Values should have a data series format with specified index which represents time order.\"\"\"\n",
    "        X = sm.add_constant(values.index)\n",
    "        model = sm.OLS(values, X).fit()\n",
    "        if give == \"slope\":\n",
    "            return model.params[1]\n",
    "        if give == \"constant\":\n",
    "            return model.params[0]\n",
    "        if give == \"model\":\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7176d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = TS_Class(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4994574",
   "metadata": {},
   "source": [
    "# explorative plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38586a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=[\"CMA_rob_bounds\",\"CMA_bounds_2sd\"], period=12, start_time=\"0:00:00\", \n",
    "             start_time_2=\"6:00:00\", include_2 = [\"CMA_rob_bounds\", \"CMA_bounds_2sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2da6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable = \"Prietok_diff_1\",include=[\"CMA_rob_bounds\",\"CMA_bounds_2sd\"], period=12,  \n",
    "             two_sided_rob_q = True, rob_q_mult = 2,\n",
    "             start_time=\"0:00:00\", start_time_2=\"6:00:00\", include_2 = [\"CMA_rob_bounds\",\"CMA_bounds_2sd\"], \n",
    "             two_sided_rob_q_2 = True, rob_q_mult_2 = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=list(\"CMA_bounds\"), period=12, variable_2 = \"Prietok_diff_1\",\n",
    "             start_time_2=\"start\", include_2 = list(\"CMA_bounds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5381def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable = \"Prietok_diff_1\", include=list(\"CMA_bounds\"), period=12, variable_2 = \"Prietok_diff_2\",\n",
    "             start_time_2=\"start\", include_2 = list(\"CMA_bounds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fdadb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b088e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee019a4f",
   "metadata": {},
   "source": [
    "# ARIMA experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c7ae95ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 32 (3.125%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 out of 32 (18.75%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 out of 32 (34.375%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 out of 32 (50.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 out of 32 (65.625%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 out of 32 (81.25%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:578: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 out of 32 (96.875%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "ts_data.get_ARIMA(5,1,5, \"ARIMA_5_1_5\", groupby = \"daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.ARIMAs_diagnostics(\"ARIMA_5_1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41861108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable_2 = \"ARIMA_5_1_5_fitted\", start_time_2 = \"start\", include=[], include_2 = [], period = 12,\n",
    "            double_plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable_2 = \"ARIMA_2_1_2_fitted\", start_time_2 = \"start\", include=[], include_2 = [], period = 12,\n",
    "            double_plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545451c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c26f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea6714d",
   "metadata": {},
   "source": [
    "# Derivatives ignoring noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b47c80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"slopes_60\"] = ts_data.data['Prietok'].rolling(window=60, center=True).apply(ts_data.get_time_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c94c7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"slopes_60\"] = ts_data.data[\"slopes_60\"]*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e20c82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ts_data.get_rob_subset(\"slopes_60\", 0.8, True)\n",
    "ts_data.data[\"slope_60_sd_L\"] =  ts_data.data[\"slopes_60\"].mean() - ts_data.data[subset][\"slopes_60\"].std()\n",
    "ts_data.data[\"slope_60_sd_U\"] = ts_data.data[\"slopes_60\"].mean() + ts_data.data[subset][\"slopes_60\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include = [\"slopes_60\",\"slope_60_sd_L\",\"slope_60_sd_U\"], period = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c258766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"slopes_15\"] = ts_data.data['Prietok'].rolling(window=15, center=True).apply(ts_data.get_time_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abbd194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"slopes_15\"] = ts_data.data[\"slopes_15\"]*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "abc8ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ts_data.get_rob_subset(\"slopes_15\", 0.8, True)\n",
    "ts_data.data[\"slopes_15_sd_L\"] =  ts_data.data[\"slopes_15\"].mean() - ts_data.data[subset][\"slopes_15\"].std()\n",
    "ts_data.data[\"slopes_15_sd_U\"] = ts_data.data[\"slopes_15\"].mean() + ts_data.data[subset][\"slopes_15\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include = [\"slopes_15\",\"slopes_15_sd_L\",\"slopes_15_sd_U\"], period = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99bdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3dd3b30",
   "metadata": {},
   "source": [
    "# ETS experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c300094",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.get_ETS(\"Prietok\", \"ETS_AAN\", groupby = None, show_progress = True, seasonal = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=list(\"CMA_bounds\"), period=12, variable_2 = \"ETS_AAN_fitted\",\n",
    "             start_time_2=\"start\", include_2 = list(\"CMA_bounds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=list(\"CMA_bounds\"), period=12, variable_2 = \"ETS_AAN_fitted\",\n",
    "             start_time_2=\"start\", double_plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e4f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79edf37a",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "13711b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data['Moving_SD_30'] = ts_data.data[\"Prietok\"].rolling(window=30, center=False).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ccb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include = list(\"MSD\", \"quant\"), window = 180, start_time_2 = \"start\",\n",
    "             include_2=list(\"CMA\",\"MA\",\"robust_avg\"), period=12, \n",
    "             variable_2 = \"Moving_SD_30\", window_2 = 180, quantile = 0.8, rob_quantile_2 = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=[\"CMA\"], period=12, window = 30,\n",
    "             start_time_2=\"start\", include_2 = [\"CMA\"], window_2 = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab297f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675c21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5610805a",
   "metadata": {},
   "source": [
    "# Fooling around with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(include=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"Prietok\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872dced",
   "metadata": {},
   "source": [
    "## grouping for rain detection based on 1 variable\n",
    "ie finding optimal cut-offs deciding for rain vs non-rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1a69dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\am\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ts_data.data[\"log_prietok\"] = np.log(data[\"Prietok\"])\n",
    "ts_data.data[\"log_prietok\"] = ts_data.data[\"log_prietok\"].replace(-np.inf, np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1009cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"exp_prietok\"] = np.exp(data[\"Prietok\"])\n",
    "cut = ts_data.data[\"exp_prietok\"].quantile(0.8)\n",
    "ts_data.data[\"exp_prietok_cut\"] = np.exp(data[\"Prietok\"]).apply(lambda x: min(x,cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"log_prietok\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"exp_prietok\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"exp_prietok_cut\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[[\"Prietok\",\"log_prietok\",\"exp_prietok\",\"exp_prietok_cut\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69a9a6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prietok              1\n",
       "log_prietok        129\n",
       "exp_prietok          1\n",
       "exp_prietok_cut      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.data[[\"Prietok\",\"log_prietok\",\"exp_prietok\",\"exp_prietok_cut\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "df751f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Kmeans(data, variables, n_clusters, n_init=10, standardize = False, nan_replace = 0, show_centers = True, \n",
    "               weights = None):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init)\n",
    "    \n",
    "    used_data = data[variables]\n",
    "    if standardize:\n",
    "        used_data = data[variables]/data[variables].std()\n",
    "    if weights is not None:\n",
    "        for i, var in enumerate(variables):\n",
    "            used_data[var] *= weights[i]\n",
    "            \n",
    "    kmeans.fit(used_data.replace(np.nan, nan_replace))\n",
    "    if show_centers:\n",
    "        print(kmeans.cluster_centers_)\n",
    "    \n",
    "    return kmeans.cluster_centers_, kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6ed11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_K_groups(data, label, variable = \"Prietok\", sort_groups = \"mean\"):\n",
    "    if sort_groups is not None:   # renaming groups according to their average value of the variable of interest\n",
    "        if sort_groups == \"count\":\n",
    "            group_means = data[label].value_counts().sort_values()\n",
    "        elif sort_groups == \"mean\":\n",
    "            group_means = data.groupby(label)[variable].mean().sort_values()\n",
    "        new_labels = {group: i for i, group in enumerate(group_means.index)}\n",
    "        data[label] = data[label].map(new_labels)\n",
    "    for lab in data[label].unique():\n",
    "        data[variable+'_group_'+str(lab)] = np.where(data[label] == lab, data[variable], np.nan)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "894f204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_K_groups(data, label, variable = \"Prietok\", fig_size=(8, 6), sort_groups = \"mean\"):\n",
    "    data = make_K_groups(data, label, variable, sort_groups = sort_groups)\n",
    "    plt.figure(figsize=fig_size)\n",
    "    unique_labels = data[label].unique()\n",
    "    unique_labels.sort()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "    # Plot each cluster separately\n",
    "    for i, lab in enumerate(unique_labels):\n",
    "        plt.plot(data['date'], data[variable+'_group_'+str(lab)], label='Group '+str(lab), color = colors[i])\n",
    "    plt.xlabel('Date and time')\n",
    "    plt.ylabel(variable)\n",
    "    plt.title(variable+\" based on \" + label)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "874d7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.87354786]\n",
      " [20.9925196 ]]\n",
      "[[0.31479639]\n",
      " [1.53351156]]\n",
      "[[11.99162717]\n",
      " [97.98864152]]\n"
     ]
    }
   ],
   "source": [
    "_, ts_data.data[\"rain_labels_1\"]= get_Kmeans(ts_data.data, [\"Prietok\"], 2)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_2\"]= get_Kmeans(ts_data.data, [\"log_prietok\"], 2, nan_replace = 1)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_3\"]= get_Kmeans(ts_data.data, [\"exp_prietok_cut\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15866f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_K_groups(ts_data.data, \"rain_labels_1\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_2\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c24ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = ts_data.data[\"Prietok\"].quantile(0.8)\n",
    "print(cut)\n",
    "ts_data.data[\"rain_labels_4\"] = ts_data.data[\"Prietok\"].apply(lambda x: 0 if x<cut else 1)\n",
    "plot_K_groups(ts_data.data, \"rain_labels_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"rain_labels_1\"]= get_Kmeans(ts_data.data, [\"Prietok\"], 3)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_2\"]= get_Kmeans(ts_data.data, [\"log_prietok\"], 3, nan_replace = 1)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_3\"]= get_Kmeans(ts_data.data, [\"exp_prietok_cut\"], 3)\n",
    "\n",
    "plot_K_groups(ts_data.data, \"rain_labels_1\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_2\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"rain_labels_1\"]= get_Kmeans(ts_data.data, [\"Prietok\"], 4)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_2\"]= get_Kmeans(ts_data.data, [\"log_prietok\"], 4, nan_replace = 1)\n",
    "\n",
    "_, ts_data.data[\"rain_labels_3\"]= get_Kmeans(ts_data.data, [\"exp_prietok_cut\"], 4)\n",
    "\n",
    "plot_K_groups(ts_data.data, \"rain_labels_1\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_2\")\n",
    "plot_K_groups(ts_data.data, \"rain_labels_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4c06302",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data = make_K_groups(ts_data.data, \"rain_labels_1\", \"Prietok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable = 'Prietok_group_0',include=[\"Prietok_group_1\",\"Prietok_group_2\",\"Prietok_group_3\"],period=12,\n",
    "            marker = \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5eaa03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data = make_K_groups(ts_data.data, \"rain_labels_2\", \"Prietok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd46321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.plot(variable = 'Prietok_group_0',include=[\"Prietok_group_1\",\"Prietok_group_2\",\"Prietok_group_3\"],period=12,\n",
    "            marker = \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840cb4a2",
   "metadata": {},
   "source": [
    "### Why are groups based on exponential and logarithm mixing? There are observations which are eg. in the lowest group but observation with smaller flow are in the group of larger flows, which should not happen for simple grouping based on 1 variable which is a strictly monotonic transformation of the flow...\n",
    "\n",
    "#### note for rain detection: making different groupings for night (23:00-5:00) and day (separate datasets or add indicator as the second variable to KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54464abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29fa0e04",
   "metadata": {},
   "source": [
    "## General clustering exploration based on additional engineered features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bb135",
   "metadata": {},
   "source": [
    "* try making new variables indicating time periods, or moving measure etc as additional input for clustering\n",
    "* scaling of multiple variables - standardize, choose weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8e120262",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data['MA_30'] = ts_data.data[\"Prietok\"].rolling(window=30, center=True).mean()\n",
    "ts_data.data['Moving_SD_30'] = ts_data.data[\"Prietok\"].rolling(window=30, center=True).std()\n",
    "ts_data.data['MA_5'] = ts_data.data[\"Prietok\"].rolling(window=5, center=True).mean()\n",
    "ts_data.data['MA_15'] = ts_data.data[\"Prietok\"].rolling(window=15, center=True).mean()\n",
    "ts_data.data['Moving_SD_15'] = ts_data.data[\"Prietok\"].rolling(window=15, center=True).std()\n",
    "\n",
    "ts_data.data['MA_90'] = ts_data.data[\"Prietok\"].rolling(window=90, center=True).mean()  # 3h\n",
    "ts_data.data['Moving_SD_90'] = ts_data.data[\"Prietok\"].rolling(window=90, center=True).std()\n",
    "ts_data.data['MA_180'] = ts_data.data[\"Prietok\"].rolling(window=180, center=True).mean()  #6h\n",
    "ts_data.data['Moving_SD_180'] = ts_data.data[\"Prietok\"].rolling(window=180, center=True).std()\n",
    "\n",
    "#ts_data.data[\"slopes_15\"] = ts_data.data['Prietok'].rolling(window=15, center=True).apply(ts_data.get_time_trend)\n",
    "#ts_data.data[\"slopes_30\"] = ts_data.data['Prietok'].rolling(window=30, center=True).apply(ts_data.get_time_trend)\n",
    "#ts_data.data[\"slopes_60\"] = ts_data.data['Prietok'].rolling(window=60, center=True).apply(ts_data.get_time_trend)\n",
    "\n",
    "ts_data.data['index'] = ts_data.data.index\n",
    "\n",
    "hours = ts_data.data['date'].dt.hour\n",
    "ts_data.data['day']  = ((hours < 23) & (hours >= 5)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c6433f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data[\"slopes_15\"] = slopes_15\n",
    "ts_data.data[\"slopes_30\"] = slopes_30\n",
    "ts_data.data[\"slopes_60\"] = slopes_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "70c58fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MA_5','MA_15','MA_30','MA_90','MA_180','Moving_SD_15','Moving_SD_30','Moving_SD_90','Moving_SD_180',\n",
    "           \"slopes_15\", \"slopes_30\", \"slopes_60\", \"index\", \"day\", \"Prietok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "22e25a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48839498 0.23725445 0.58531512]\n",
      " [2.90238041 3.40237837 3.11750542]\n",
      " [5.85959029 4.15312599 5.66510176]\n",
      " [1.18403036 0.7463138  1.42057984]]\n",
      "[[0.44619762 0.49063999 0.24627429 0.59626144]\n",
      " [2.67246999 3.11547652 3.76627429 3.31784755]\n",
      " [1.12175571 1.2033228  0.76021043 1.43341033]\n",
      " [6.00569463 6.03248847 3.7945075  5.70451265]]\n"
     ]
    }
   ],
   "source": [
    "_, ts_data.data[\"clusters_1\"]= get_Kmeans(ts_data.data, ['MA_30','Moving_SD_30','MA_90'], \n",
    "                                             4, standardize = True, weights = None)\n",
    "\n",
    "_, ts_data.data[\"clusters_2\"]= get_Kmeans(ts_data.data, [\"Prietok\",'MA_30','Moving_SD_30','MA_90'], \n",
    "                                             4, standardize = True, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b914e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_K_groups(ts_data.data, \"clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"clusters_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_1\"]= get_Kmeans(ts_data.data, ['MA_30','Moving_SD_30','Moving_SD_90'], \n",
    "                                             4, standardize = True, weights = None, show_centers = False)\n",
    "\n",
    "_, ts_data.data[\"clusters_2\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_30','Moving_SD_30','MA_90'], \n",
    "                                             4, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_3\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_30','Moving_SD_30','MA_90'], \n",
    "                                             4, standardize = True, weights = [1,3,1,1], show_centers = False)\n",
    "_, ts_data.data[\"clusters_4\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_5','Moving_SD_30','MA_90'], \n",
    "                                             4, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_5\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_5','Moving_SD_30','MA_90'], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"clusters_2\")\n",
    "plot_K_groups(ts_data.data, \"clusters_3\")\n",
    "plot_K_groups(ts_data.data, \"clusters_4\")\n",
    "plot_K_groups(ts_data.data, \"clusters_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976eb18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_1\"]= get_Kmeans(ts_data.data, ['MA_30','Moving_SD_30','Moving_SD_90'], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "\n",
    "_, ts_data.data[\"clusters_2\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_30','Moving_SD_30','MA_90'], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_3\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_30','Moving_SD_30','MA_90'], \n",
    "                                             2, standardize = True, weights = [1,3,1,1], show_centers = False)\n",
    "_, ts_data.data[\"clusters_4\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_5','Moving_SD_30','MA_90'], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_5\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",'MA_5','Moving_SD_30','MA_90',\"index\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"clusters_2\")\n",
    "plot_K_groups(ts_data.data, \"clusters_3\")\n",
    "plot_K_groups(ts_data.data, \"clusters_4\")\n",
    "plot_K_groups(ts_data.data, \"clusters_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90671a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_i\"]= get_Kmeans(ts_data.data, [\"index\",'Moving_SD_30'], \n",
    "                                             2, standardize = True, weights = [1,5], show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927264fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_1\"]= get_Kmeans(ts_data.data, [\"MA_5\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_2\"]= get_Kmeans(ts_data.data, [\"MA_30\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_3\"]= get_Kmeans(ts_data.data, [\"Moving_SD_30\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_4\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"clusters_2\")\n",
    "plot_K_groups(ts_data.data, \"clusters_3\")\n",
    "plot_K_groups(ts_data.data, \"clusters_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01313927",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_1\"]= get_Kmeans(ts_data.data, [\"MA_5\",\"index\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_2\"]= get_Kmeans(ts_data.data, [\"MA_30\",\"index\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_3\"]= get_Kmeans(ts_data.data, [\"Moving_SD_30\",\"index\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_4\"]= get_Kmeans(ts_data.data, [\"Moving_SD_90\",\"index\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"clusters_2\")\n",
    "plot_K_groups(ts_data.data, \"clusters_3\")\n",
    "plot_K_groups(ts_data.data, \"clusters_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_i\"]= get_Kmeans(ts_data.data, [\"index\",'Moving_SD_90',\"MA_5\"], \n",
    "                                             2, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a668f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"clusters_i\"]= get_Kmeans(ts_data.data, ['Moving_SD_30',\"MA_30\"], \n",
    "                                             7, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_i2\"]= get_Kmeans(ts_data.data, ['Moving_SD_30',\"MA_30\",\"index\"], \n",
    "                                             7, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"clusters_i3\"]= get_Kmeans(ts_data.data, ['Moving_SD_30',\"MA_30\",\"index\"], \n",
    "                                             7, standardize = True, weights = [1,1,0.3], show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"clusters_i\")\n",
    "plot_K_groups(ts_data.data, \"clusters_i2\")\n",
    "plot_K_groups(ts_data.data, \"clusters_i3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf890c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8b5534d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MA_5',\n",
       " 'MA_15',\n",
       " 'MA_30',\n",
       " 'MA_90',\n",
       " 'MA_180',\n",
       " 'Moving_SD_15',\n",
       " 'Moving_SD_30',\n",
       " 'Moving_SD_90',\n",
       " 'Moving_SD_180',\n",
       " 'slopes_15',\n",
       " 'slopes_30',\n",
       " 'slopes_60',\n",
       " 'index',\n",
       " 'day',\n",
       " 'Prietok']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc8729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_data.data[\"general_clusters_1\"]= get_Kmeans(ts_data.data, features, \n",
    "                                             7, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"general_clusters_2\"]= get_Kmeans(ts_data.data, ['MA_15','MA_90','Moving_SD_30','slopes_30','day'], \n",
    "                                             7, standardize = True, weights = None, show_centers = False)\n",
    "_, ts_data.data[\"general_clusters_3\"]= get_Kmeans(ts_data.data, ['MA_15','MA_90','Moving_SD_30','slopes_30','day',\"index\"], \n",
    "                                             7, standardize = True, weights = None, show_centers = False)\n",
    "plot_K_groups(ts_data.data, \"general_clusters_1\")\n",
    "plot_K_groups(ts_data.data, \"general_clusters_2\")\n",
    "plot_K_groups(ts_data.data, \"general_clusters_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d7ce1d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.nan,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data = make_K_groups(ts_data.data, \"general_clusters_1\", \"Prietok\", sort_groups = \"count\")\n",
    "\n",
    "n=7\n",
    "include = [\"Prietok_group_\"+str(i) for i in range(1,n)]\n",
    "ts_data.plot(variable = 'Prietok_group_0',include=include,period=12,\n",
    "            marker = \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a10eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data = make_K_groups(ts_data.data, \"general_clusters_2\", \"Prietok\", sort_groups = \"count\")\n",
    "\n",
    "n=7\n",
    "include = [\"Prietok_group_\"+str(i) for i in range(1,n)]\n",
    "ts_data.plot(variable = 'Prietok_group_0',include=include,period=12,\n",
    "            marker = \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.data = make_K_groups(ts_data.data, \"general_clusters_3\", \"Prietok\", sort_groups = \"count\")\n",
    "\n",
    "n=7\n",
    "include = [\"Prietok_group_\"+str(i) for i in range(1,n)]\n",
    "ts_data.plot(variable = 'Prietok_group_0',include=include,period=12,\n",
    "            marker = \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5dc178",
   "metadata": {},
   "source": [
    "nans as extremes - something about names of the groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9ef3b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = ['Prietok_group_0'] + include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d5ee4099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.data[include].isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ee6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
